{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7RxKrZOXtI0"
   },
   "source": [
    "## 1. Mount Drive Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "eThUeauoQdqX",
    "outputId": "4aad107c-79ba-49b8-f929-3f09acca98ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "zHWuD8YtZsE0",
    "outputId": "17765383-8f05-49eb-eed5-65cedaba06d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3MB 7.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
      "\u001b[K     |████████████████████████████████| 901kB 31.4MB/s \n",
      "\u001b[?25hCollecting huggingface-hub==0.0.8\n",
      "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3MB 44.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Installing collected packages: sacremoses, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "id": "hcUezaMfazCC"
   },
   "outputs": [],
   "source": [
    "## Imports\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf ## check for tf_gpu\n",
    "from transformers import TFDistilBertForSequenceClassification\n",
    "import numpy as np\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwTQQPGbabJT"
   },
   "source": [
    "## 3. Read Data (Train and Test) + Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "id": "T6oycF61RNZe"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"drive/MyDrive/colab_work/intent_classification/input/data/v2/train/sofmattress_train.csv\")\n",
    "test = pd.read_csv(\"drive/MyDrive/colab_work/intent_classification/input/data/v2/test/sofmattress_test.csv\")\n",
    "\n",
    "label_to_no_dict = {};no_to_label_dict = {}\n",
    "l = train['label'].unique()\n",
    "for i in range(len(l)):\n",
    "  label_to_no_dict[l[i]] = i\n",
    "  no_to_label_dict[i] = l[i]\n",
    "\n",
    "label_to_no_dict['NO_NODES_DETECTED'] = len(l)\n",
    "no_to_label_dict[len(l)] = 'NO_NODES_DETECTED'\n",
    "\n",
    "train['label_value'] = train['label'].map(label_to_no_dict)\n",
    "test['label_value'] = test['label'].map(label_to_no_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "collapsed": false,
    "id": "SvdJG-8UZx68",
    "outputId": "ad686ec4-4889-498f-9379-906362518461"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>label_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>May I please know about the offers</td>\n",
       "      <td>OFFERS</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>Available offers</td>\n",
       "      <td>OFFERS</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>Is offer available</td>\n",
       "      <td>OFFERS</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>Want to know the discount</td>\n",
       "      <td>OFFERS</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>Tell me about the latest offers</td>\n",
       "      <td>OFFERS</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               sentence   label  label_value\n",
       "323  May I please know about the offers  OFFERS           20\n",
       "324                    Available offers  OFFERS           20\n",
       "325                  Is offer available  OFFERS           20\n",
       "326          Want to know the discount   OFFERS           20\n",
       "327     Tell me about the latest offers  OFFERS           20"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "collapsed": false,
    "id": "BbrevJYPZ2_F",
    "outputId": "954c70cb-62cb-4f46-db3c-529b381941fc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>label_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There are only 2 models</td>\n",
       "      <td>NO_NODES_DETECTED</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Single</td>\n",
       "      <td>NO_NODES_DETECTED</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What's difference between ergo and ortho</td>\n",
       "      <td>COMPARISON</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Return order</td>\n",
       "      <td>RETURN_EXCHANGE</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hai not recieved my product</td>\n",
       "      <td>DELAY_IN_DELIVERY</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   sentence              label  label_value\n",
       "0                   There are only 2 models  NO_NODES_DETECTED           21\n",
       "1                                    Single  NO_NODES_DETECTED           21\n",
       "2  What's difference between ergo and ortho         COMPARISON            4\n",
       "3                              Return order    RETURN_EXCHANGE           17\n",
       "4               Hai not recieved my product  DELAY_IN_DELIVERY           15"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6U7aQg-bG0y"
   },
   "source": [
    "## 4. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train, Val and Test Creation\n",
    "* Getting train, Test, Val data in right format \n",
    "* Initialize DistilBert Tokenizer and get encodings\n",
    "* Get Train, Val and Test data using TensorFlow Slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165,
     "referenced_widgets": [
      "0898de5e24ef48de9f421f0fb856ab1d",
      "cc51377f4dc14d5498da254b71d40d47",
      "f36a72e8d0c7464fb3c1c14eac471823",
      "242d32bab5e245598a2732eb73d4ca7d",
      "7ccaf4b64b46413985c3769e2aa1d400",
      "c212eb953b9542109f2713a58ff87f9e",
      "8fe5b059bdd547289d580365c21e7257",
      "23c0840ba4bb41508d96a47ef23194cd",
      "734df0eaa69d4973b86f03b16d79a8b7",
      "f390ba64694d49f78a95c997dcc4ed56",
      "479d9881dfae498d83c1f7f309972d24",
      "9ed05d2b4cde4044a7c940092e85305e",
      "8dd76a3491c54841a6eee1caf62fe339",
      "c88d4f6ba49d4337823d822f4189a036",
      "f5f07635486f420eb963ba04db8f0d87",
      "ab964204b1fd47dfa7eafc281ecb35fb",
      "d3618e5981cc4c2487f86b38af3a867f",
      "d2639b961d2b4ed7b58fc0fce4120699",
      "eed2d6fd325742da93b1ddbc6ed825b6",
      "fdeea665aebf4f66b61811004b428636",
      "684756178e0240f1bacfa4052047b11a",
      "845cf68d23c949c8933513dfc04bc33e",
      "244382e8f94c433e90621f87e5ef8204",
      "a08d283383ec42febad31876e2ea88a8"
     ]
    },
    "collapsed": false,
    "id": "3hF3XLglaTgk",
    "outputId": "cd942723-c89b-42e1-9ba5-20d223b30b2e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0898de5e24ef48de9f421f0fb856ab1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "734df0eaa69d4973b86f03b16d79a8b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3618e5981cc4c2487f86b38af3a867f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## 4.1 Train, Val and Test Creation -- (Training data size very less, but still lets create validation set)\n",
    "train_texts, val_texts,train_labels, val_labels = train_test_split(train['sentence'].values,\\\n",
    "                                                                   train['label_value'].values, test_size=0.2,\\\n",
    "                                                                   random_state=42, stratify = train['label_value'].values)\n",
    "## 4.2 Getting train, Test, Val data in right format \n",
    "test_texts = test['sentence'].values\n",
    "test_labels = test['label_value'].values\n",
    "\n",
    "train_texts = list(train_texts);val_texts = list(val_texts);test_texts = list(test_texts)\n",
    "train_labels = list(train_labels);val_labels - list(val_labels); test_labels = list(test_labels)\n",
    "\n",
    "## 4.3 Initialize DistilBert Tokenizer and get encodings\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True)\n",
    "\n",
    "## 4.4  Get Train, Val and Test data using TensorFlow Slices\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    "))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    val_labels\n",
    "))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(test_encodings),\n",
    "    test_labels\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQzefgT0bwRw"
   },
   "source": [
    "## 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "0nResUISdPvS",
    "outputId": "c18a42bc-014b-4ee8-867b-2d65267bec75"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_layer_norm', 'vocab_transform', 'activation_13', 'vocab_projector']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier', 'dropout_119', 'pre_classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "17/17 [==============================] - 54s 3s/step - loss: 2.9887 - accuracy: 0.1260\n",
      "Epoch 2/7\n",
      "17/17 [==============================] - 44s 3s/step - loss: 2.6247 - accuracy: 0.4389\n",
      "Epoch 3/7\n",
      "17/17 [==============================] - 43s 3s/step - loss: 2.0004 - accuracy: 0.7366\n",
      "Epoch 4/7\n",
      "17/17 [==============================] - 43s 3s/step - loss: 1.3759 - accuracy: 0.8511\n",
      "Epoch 5/7\n",
      "17/17 [==============================] - 43s 3s/step - loss: 0.8859 - accuracy: 0.9466\n",
      "Epoch 6/7\n",
      "17/17 [==============================] - 43s 3s/step - loss: 0.5411 - accuracy: 0.9771\n",
      "Epoch 7/7\n",
      "17/17 [==============================] - 43s 3s/step - loss: 0.3294 - accuracy: 0.9962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0b521e3b90>"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased',num_labels = len(l))\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=6e-5)\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.0004)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=optimizer, loss=model.compute_loss, metrics = [metric]) # can also use any keras loss fn\n",
    "# model.compile(optimizer=optimizer, loss=loss, metrics=[metric]) # can also use any keras loss fn\n",
    "model.fit(train_dataset.shuffle(1000).batch(16), epochs = 7, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuATw2T-emYp"
   },
   "source": [
    "## 6. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "y7r-f1LfzKYW",
    "outputId": "da37b420-dec4-496e-97d2-39f140a6da31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Value Counts b/w True and Pred Label :\n",
      " True     323\n",
      "False      5\n",
      "dtype: int64\n",
      "Accuracy\n",
      " : 98.48\n",
      "=======\n",
      "Validation: \n",
      "Value Counts b/w True and Pred Label :\n",
      " True     61\n",
      "False     5\n",
      "dtype: int64\n",
      "Accuracy\n",
      " : 92.42\n",
      "=======\n",
      "Test: \n",
      "Value Counts b/w True and Pred Label :\n",
      " False    223\n",
      "True     174\n",
      "dtype: int64\n",
      "Accuracy\n",
      " : 43.83\n",
      "=======\n"
     ]
    }
   ],
   "source": [
    "def fn_prediction(df,model):\n",
    "  l1=[];l2=[];l3=[]\n",
    "  for ind, info in df.iterrows():\n",
    "    predict_input = tokenizer.encode(info['sentence'],\n",
    "                                  truncation=True,\n",
    "                                  padding=True,\n",
    "                                  return_tensors=\"tf\")\n",
    "    tf_output = model.predict(predict_input)[0]\n",
    "    tf_prediction = tf.nn.softmax(tf_output, axis=1).numpy()[0]\n",
    "    l1.append(no_to_label_dict[np.argmax(tf_prediction)])\n",
    "    l2.append(np.max(tf_prediction))\n",
    "    d = {}\n",
    "    for i in range(len(tf_prediction)):\n",
    "      d[no_to_label_dict[i]] = tf_prediction[i]\n",
    "    l3.append(d)\n",
    "  df['pred_label'] = l1\n",
    "  df['max_pred_prob'] = l2\n",
    "  df['all_prob'] = l3\n",
    "  df['status'] = (df['label']==df['pred_label'])\n",
    "  print(\"Value Counts b/w True and Pred Label :\\n {}\".format((df['label']==df['pred_label']).value_counts()))\n",
    "  print(\"Accuracy\\n : {}\".format(round((df[df['status']==True].shape[0]/df.shape[0])*100,2)))\n",
    "  print(\"=======\")\n",
    "  return df\n",
    "\n",
    "print(\"Training: \")\n",
    "train_pred = fn_prediction(df = train, model = model)\n",
    "\n",
    "print(\"Validation: \")\n",
    "df_val = pd.DataFrame({'sentence':val_texts,'label':val_labels})\n",
    "df_val['label'] = df_val['label'].map(no_to_label_dict)\n",
    "val_pred = fn_prediction(df = df_val, model = model)\n",
    "\n",
    "print(\"Test: \")\n",
    "test_pred = fn_prediction(df = test, model = model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Model seems highly **overfit**. Need to apply some Regularization Techniques (Dropout, Learning Rate, Epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2KNxxfM1hhrn"
   },
   "source": [
    "## 7. Threshold Callibration for class value - 'No_NODES_DETECTED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "collapsed": false,
    "id": "7_6IuRtqhvG2",
    "outputId": "6dfaecc2-5ec8-45d5-a451-161d68fa64df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    323.000000\n",
       "mean       0.821734\n",
       "std        0.115923\n",
       "min        0.328941\n",
       "25%        0.754382\n",
       "50%        0.861914\n",
       "75%        0.910777\n",
       "max        0.945839\n",
       "Name: max_pred_prob, dtype: float64"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    61.000000\n",
       "mean      0.801173\n",
       "std       0.145571\n",
       "min       0.328941\n",
       "25%       0.765798\n",
       "50%       0.850869\n",
       "75%       0.905831\n",
       "max       0.940842\n",
       "Name: max_pred_prob, dtype: float64"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_pred[train_pred['status'] == True]['max_pred_prob'].describe())\n",
    "display(val_pred[val_pred['status'] == True]['max_pred_prob'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "qF8a05PfhoAn",
    "outputId": "ac467ab0-a6de-4ec5-8d40-3ff3d6704208"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: \n",
      " True     0.969512\n",
      "False    0.030488\n",
      "dtype: float64\n",
      "=========\n",
      "Val Accuracy: \n",
      " True     0.878788\n",
      "False    0.121212\n",
      "dtype: float64\n",
      "=========\n",
      "Test Accuracy: \n",
      " True     0.672544\n",
      "False    0.327456\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def get_new_status(row):\n",
    "    if row['max_pred_prob']>=0.45:\n",
    "        return row['pred_label']\n",
    "    return 'NO_NODES_DETECTED'\n",
    "\n",
    "\n",
    "train_pred['pred_new_label'] = train_pred.apply(get_new_status,axis = 1)\n",
    "val_pred['pred_new_label'] = val_pred.apply(get_new_status,axis = 1)\n",
    "test_pred['pred_new_label'] = test_pred.apply(get_new_status,axis = 1)\n",
    "\n",
    "print(\"Training Accuracy: \\n {}\".format((train_pred['pred_new_label']==train_pred['label']).value_counts(normalize = True)))\n",
    "print(\"=========\")\n",
    "print(\"Val Accuracy: \\n {}\".format((val_pred['pred_new_label']==val_pred['label']).value_counts(normalize = True)))\n",
    "print(\"=========\")\n",
    "print(\"Test Accuracy: \\n {}\".format((test_pred['pred_new_label']==test_pred['label']).value_counts(normalize = True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HhERNGX4kYKE"
   },
   "source": [
    "## 8. Saving Results\n",
    "## To-Do : Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "id": "sOunlNLFzWHm"
   },
   "outputs": [],
   "source": [
    "train_pred.to_csv('drive/MyDrive/colab_work/intent_classification/output/train_res_hug_distilbert_tf_5_epoch.csv',index = False)\n",
    "val_pred.to_csv('drive/MyDrive/colab_work/intent_classification/output/train_res_hug_distilbert_tf_5_epoch.csv',index = False)\n",
    "test_pred.to_csv('drive/MyDrive/colab_work/intent_classification/output/train_res_hug_distilbert_tf_5_epoch.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJuiekJbhG5H"
   },
   "source": [
    "## 9. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "9d2BqDi8pxHk",
    "outputId": "cefbb2cd-c65a-40f1-bfc5-6860d2a24491"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 'WHAT_SIZE_TO_ORDER')"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = \"What about size\"\n",
    "# ,\"News anchor hits back at viewer who sent her snarky note about ‘showing too much cleavage’ during broadcast\"]\n",
    "predict_input = tokenizer.encode(test_sentence,\n",
    "                                 truncation=True,\n",
    "                                 padding=True,\n",
    "                                 return_tensors=\"tf\")\n",
    "tf_output = model.predict(predict_input)[0]\n",
    "# tf_output\n",
    "tf_prediction = tf.nn.softmax(tf_output, axis=1).numpy()[0]\n",
    "np.argmax(tf_prediction),no_to_label_dict[np.argmax(tf_prediction)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ced6dSEghLdF"
   },
   "source": [
    "## END"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2.0.HuggingFaceDistilBertTF.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
